{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dd6adb",
   "metadata": {},
   "source": [
    "# Uploading yellow taxi trip data to postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eb93c",
   "metadata": {},
   "source": [
    "We start off by importing a few packages that we need.\n",
    "* Time for benchmarking\n",
    "* pandas for storing data in dataframes and offloading to pg\n",
    "* pyarrow for handling parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fad0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a8e30",
   "metadata": {},
   "source": [
    "first thing we do is we want to fammiliarize ourself with the file so we cam read the metadata for the parquet file. parquet has metadata thats readily available unlike other file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad4be853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.FileMetaData object at 0x11f9acb30>\n",
      "  created_by: parquet-cpp-arrow version 7.0.0\n",
      "  num_columns: 19\n",
      "  num_rows: 1369769\n",
      "  num_row_groups: 1\n",
      "  format_version: 1.0\n",
      "  serialized_size: 10382\n"
     ]
    }
   ],
   "source": [
    "print(pq.read_metadata(\"yellow_tripdata_2021-01.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f65ec5",
   "metadata": {},
   "source": [
    "now that we have some info on what the parquet file looks like we can go onto loading the contents of the file. we use `pq.ParquetFile()` to load a parquet into python. however you may notice that this isnt a df its just an object of parquet file. we will need to actually read this data and load that read data into a dataframe.\n",
    "\n",
    "so to do that we can use `read()` and store it in another variable called `table`\n",
    "\n",
    "now this becomes a pyarrow table which is close to a traditional df. \n",
    "\n",
    "we can use `table.schema` to look at the table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1f9b159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyarrow.parquet.core.ParquetFile'>\n",
      "<class 'pyarrow.lib.Table'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VendorID: int64\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "passenger_count: double\n",
       "trip_distance: double\n",
       "RatecodeID: double\n",
       "store_and_fwd_flag: string\n",
       "PULocationID: int64\n",
       "DOLocationID: int64\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "airport_fee: double\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 2492"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pq.ParquetFile(\"yellow_tripdata_2021-01.parquet\")\n",
    "print(type(file))\n",
    "table = file.read()\n",
    "print(type(table))\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fe7ec",
   "metadata": {},
   "source": [
    "now that we have a table we can use another pyarrow method to convert the table to a pandas df, `table.to_pandas()`\n",
    "\n",
    "from this we get a pandas dataframe for our pyarrow table. and now were ready to do normal pandas work on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b126a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369769 entries, 0 to 1369768\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   VendorID               1369769 non-null  int64         \n",
      " 1   tpep_pickup_datetime   1369769 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  1369769 non-null  datetime64[us]\n",
      " 3   passenger_count        1271417 non-null  float64       \n",
      " 4   trip_distance          1369769 non-null  float64       \n",
      " 5   RatecodeID             1271417 non-null  float64       \n",
      " 6   store_and_fwd_flag     1271417 non-null  object        \n",
      " 7   PULocationID           1369769 non-null  int64         \n",
      " 8   DOLocationID           1369769 non-null  int64         \n",
      " 9   payment_type           1369769 non-null  int64         \n",
      " 10  fare_amount            1369769 non-null  float64       \n",
      " 11  extra                  1369769 non-null  float64       \n",
      " 12  mta_tax                1369769 non-null  float64       \n",
      " 13  tip_amount             1369769 non-null  float64       \n",
      " 14  tolls_amount           1369769 non-null  float64       \n",
      " 15  improvement_surcharge  1369769 non-null  float64       \n",
      " 16  total_amount           1369769 non-null  float64       \n",
      " 17  congestion_surcharge   1271417 non-null  float64       \n",
      " 18  airport_fee            5 non-null        float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 198.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = table.to_pandas()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ad88b",
   "metadata": {},
   "source": [
    "now over here these two timestamp rows needed to be casted to a datetime so we use `pd.to_datetime(df.<col_name>)` to cast the entire column to the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabf051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2021-01-01 00:36:12\n",
       "1         2021-01-01 00:52:19\n",
       "2         2021-01-01 01:11:06\n",
       "3         2021-01-01 00:31:01\n",
       "4         2021-01-01 00:48:21\n",
       "                  ...        \n",
       "1369764   2021-01-31 23:33:00\n",
       "1369765   2021-01-31 23:51:00\n",
       "1369766   2021-01-31 23:38:00\n",
       "1369767   2021-02-01 00:02:03\n",
       "1369768   2021-01-31 23:31:22\n",
       "Name: tpep_dropoff_datetime, Length: 1369769, dtype: datetime64[us]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df.tpep_pickup_datetime)\n",
    "pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b41bb",
   "metadata": {},
   "source": [
    "so now that we have our data in pandas we need to ingest this into pg. now to do that we need to connect to the db somehow and we do that by using `create_engine` and then pass into `to_sql` as the connection object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a159e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1754d4",
   "metadata": {},
   "source": [
    "so here what were doing is actually creating the engine and were doing `postgresql+psycopg` (dialect+driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de6b99ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x1282a79d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql+psycopg://root:root@localhost:5432/ny_taxi', pool_pre_ping=True)\n",
    "engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tairport_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59670bfa",
   "metadata": {},
   "source": [
    "since our dataset is huge (over a million records) we dont want to ingest this all at once. and its good practice for even larget datasets where we will need to batch insert anyways. so over here we create an iterator using `iter_batches(batchsize=)`\n",
    "this is another pyarrow parquet method. it creates an iterator to iterate over the parquet file in batches. \n",
    "\n",
    "like a normal iterator in python we use `next(<iter_obj>)` to iterate over it.\n",
    "\n",
    "here were setting batch size to 100000 so it will take us 14 iterations to go over 1.3 million records. now each iteration of `branches_iter` is a new parquet batch which we can load into pandas using `to_pandas()`\n",
    "\n",
    "and thats how were gonna load all the batches. we loop using this iterator.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdb3914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-04 14:04:31</td>\n",
       "      <td>2021-01-04 14:08:52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-04 14:18:46</td>\n",
       "      <td>2021-01-04 14:35:45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.35</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-04 14:42:41</td>\n",
       "      <td>2021-01-04 14:59:22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.35</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-04 14:39:02</td>\n",
       "      <td>2021-01-04 15:09:37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>60.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-04 14:49:36</td>\n",
       "      <td>2021-01-04 14:54:44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0             1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1             1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2             1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3             1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4             2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...         ...                  ...                   ...              ...   \n",
       "99995         1  2021-01-04 14:04:31   2021-01-04 14:08:52              3.0   \n",
       "99996         1  2021-01-04 14:18:46   2021-01-04 14:35:45              2.0   \n",
       "99997         1  2021-01-04 14:42:41   2021-01-04 14:59:22              2.0   \n",
       "99998         2  2021-01-04 14:39:02   2021-01-04 15:09:37              2.0   \n",
       "99999         2  2021-01-04 14:49:36   2021-01-04 14:54:44              5.0   \n",
       "\n",
       "       trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0               2.10         1.0                  N           142   \n",
       "1               0.20         1.0                  N           238   \n",
       "2              14.70         1.0                  N           132   \n",
       "3              10.60         1.0                  N           138   \n",
       "4               4.94         1.0                  N            68   \n",
       "...              ...         ...                ...           ...   \n",
       "99995           0.70         1.0                  N           234   \n",
       "99996           3.30         1.0                  N           234   \n",
       "99997           4.70         1.0                  N           236   \n",
       "99998          17.95         2.0                  N           132   \n",
       "99999           0.37         1.0                  N           236   \n",
       "\n",
       "       DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                43             2          8.0    3.0      0.5        0.00   \n",
       "1               151             2          3.0    0.5      0.5        0.00   \n",
       "2               165             1         42.0    0.5      0.5        8.65   \n",
       "3               132             1         29.0    0.5      0.5        6.05   \n",
       "4                33             1         16.5    0.5      0.5        4.06   \n",
       "...             ...           ...          ...    ...      ...         ...   \n",
       "99995           224             2          5.0    2.5      0.5        0.00   \n",
       "99996           236             1         14.5    2.5      0.5        3.55   \n",
       "99997            79             1         17.0    2.5      0.5        4.05   \n",
       "99998           148             1         52.0    0.0      0.5        5.00   \n",
       "99999           236             2          5.0    0.0      0.5        0.00   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0               0.0                    0.3         11.80   \n",
       "1               0.0                    0.3          4.30   \n",
       "2               0.0                    0.3         51.95   \n",
       "3               0.0                    0.3         36.35   \n",
       "4               0.0                    0.3         24.36   \n",
       "...             ...                    ...           ...   \n",
       "99995           0.0                    0.3          8.30   \n",
       "99996           0.0                    0.3         21.35   \n",
       "99997           0.0                    0.3         24.35   \n",
       "99998           0.0                    0.3         60.30   \n",
       "99999           0.0                    0.3          8.30   \n",
       "\n",
       "       congestion_surcharge  airport_fee  \n",
       "0                       2.5          NaN  \n",
       "1                       0.0          NaN  \n",
       "2                       0.0          NaN  \n",
       "3                       0.0          NaN  \n",
       "4                       2.5          NaN  \n",
       "...                     ...          ...  \n",
       "99995                   2.5          NaN  \n",
       "99996                   2.5          NaN  \n",
       "99997                   2.5          NaN  \n",
       "99998                   2.5          NaN  \n",
       "99999                   2.5          NaN  \n",
       "\n",
       "[100000 rows x 19 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branches_iter = file.iter_batches(batch_size=100000)\n",
    "branches_iter\n",
    "\n",
    "df = next(branches_iter).to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952a0f0",
   "metadata": {},
   "source": [
    "this is how that would look with some basic batch counting and benchmarking we create that iterator and loop over it in the loop defitinion. the for each batch we load that into a df and then load that into sql and we pass it that db connection engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89127298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting batch 1...\n",
      "inserted! Total time taken is      1.927 seconds.\n",
      "\n",
      "inserting batch 2...\n",
      "inserted! Total time taken is      1.704 seconds.\n",
      "\n",
      "inserting batch 3...\n",
      "inserted! Total time taken is      1.692 seconds.\n",
      "\n",
      "inserting batch 4...\n",
      "inserted! Total time taken is      1.794 seconds.\n",
      "\n",
      "inserting batch 5...\n",
      "inserted! Total time taken is      1.771 seconds.\n",
      "\n",
      "inserting batch 6...\n",
      "inserted! Total time taken is      1.741 seconds.\n",
      "\n",
      "inserting batch 7...\n",
      "inserted! Total time taken is      1.764 seconds.\n",
      "\n",
      "inserting batch 8...\n",
      "inserted! Total time taken is      1.780 seconds.\n",
      "\n",
      "inserting batch 9...\n",
      "inserted! Total time taken is      1.722 seconds.\n",
      "\n",
      "inserting batch 10...\n",
      "inserted! Total time taken is      1.710 seconds.\n",
      "\n",
      "inserting batch 11...\n",
      "inserted! Total time taken is      1.702 seconds.\n",
      "\n",
      "inserting batch 12...\n",
      "inserted! Total time taken is      1.749 seconds.\n",
      "\n",
      "inserting batch 13...\n",
      "inserted! Total time taken is      1.681 seconds.\n",
      "\n",
      "inserting batch 14...\n",
      "inserted! Total time taken is      1.282 seconds.\n",
      "\n",
      "completed! Total Time taken was     24.114 seconds for 14 batches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "count = 0\n",
    "for batch in file.iter_batches(batch_size=100000):\n",
    "    count+=1\n",
    "    batch_df = batch.to_pandas()\n",
    "    print(f\"inserting batch {count}...\")\n",
    "    b_start = time()\n",
    "    batch_df.to_sql(name='ny_taxi_data', con=engine, if_exists='append')\n",
    "    b_end = time()\n",
    "    print(f\"inserted! Total time taken is {b_end-b_start:10.3f} seconds.\\n\")\n",
    "\n",
    "t_end = time()\n",
    "\n",
    "print(f\"completed! Total Time taken was {t_end-t_start:10.3f} seconds for {count} batches.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1d84a",
   "metadata": {},
   "source": [
    "from this we can now go to our pgcli and run a few tests.\n",
    "\n",
    "first we can run `\\dt` just to get the tables. here we can now see we have that taxi data loaded into our db. \n",
    "\n",
    "next we can run a `\\d <table_name>` to get the table schema. in the cli from this we can see the schema for this\n",
    "\n",
    "now we can look at the data itself. lets run a `SELECT count(1) from ny_taxi_data;`\n",
    "and now we can see that we have all 1.3 million records. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5528fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
